{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMSGNbaE7dG5",
        "outputId": "7aae9c00-8947-4fa9-b4e3-c78a84785f26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 商品回購預測"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "資料前處理：\n",
        "由於原始資料是以所有交易商品作為主體,將資料型態整理成一個 dataframe,當中只提取曾經買過衛生紙的消費者的所有訂單交易資訊,並由原始資料新增變數,變數有以下四種:\n",
        "I. 該商品上次購買至現在的時間長\n",
        "II. 商品 30 天內的購買頻率\n",
        "III. 顧客購買商品時為星期幾\n",
        "IV. 購買的時段(一天以每 4 小時劃分)\n",
        "\n",
        "模型配適:\n",
        "由於當中被有購買衛生紙的資料和未購買衛生紙的資料,比例相差巨大,因此採用半監督式學習(Semi-supervised Learning)的方式,搭配下採樣(undersampling)隨機取出 10000 筆衛生紙交易資訊與 15000 筆非衛生紙交易資訊進行機器學習模型的訓練,由於單一模型訓練不佳,因此我們使用 KNN、Logistic Regression、Random Forest、MLP、LGBM、XGBoost 六個模型預測,並從中挑選適合該資料的模型,只要其中 2 個模型判斷該特徵為會購買衛生紙我們及判定為會購買衛生紙,並重複抽樣 5 次取得平均。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 預測購買週期"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "以預測消費者是否會在 30 天購買為例\n",
        "\n",
        "資料前處理：\n",
        "    切割資料：切割成三份資料\n",
        "            以1~3月的資料為訓練集，預測消費者4月是否回購\n",
        "            以5~7月的資料為訓練集，預測消費者8月是否回購\n",
        "            以9~11月的資料為訓練集，預測消費者12月是否回購\n",
        "    取RFM資訊：將第一、二、三份切割資料分別探索其各自的 RFM 資訊,並將各自的 R、F、M 資訊分別使用正規化處理、正規化處理後使用Kmeans 分群的分群數,因此共有六個自變數,並分別獲得第一、二、三 RFM 資訊資料。\n",
        "模型配適:\n",
        "    將訓練及測試資料比例取 8:2,使用五種機器學習模型,分別為Random Forest Classifier(RF) 、 Multilayer Perceptron Classifier(MLP) 、eXtreme Gradient Boosting Classifier(XGBoost)、Light Gradient BoostingMachine Classifier(LightGBM) 、Logistic Regression Classifier(LR)進行配適。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4YMAhV4M03r"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import svm\n",
        "from xgboost import XGBClassifier\n",
        "import lightgbm as lgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNKurDT2NHpx",
        "outputId": "e4965cf7-c851-48da-d2cd-66a248a88e4b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ]
        }
      ],
      "source": [
        "pchome = pd.read_csv('/content/drive/MyDrive/Co-lab/dataset/2021datapilot_PChome.csv')\n",
        "pchome.rename(columns={'Unnamed: 0':'MEM_ID', 'Unnamed: 1':'POSTAL_CD','Unnamed: 2':'ORDER_ID'}, inplace = True)\n",
        "pchome['DATE_CD'] = pd.to_datetime(pchome['DATE_CD'])\n",
        "pchome['TIME_CD'] = pd.to_datetime(pchome['TIME_CD'])\n",
        "pchome['PRICE'] = pchome['PRICE'].str.replace(',','').str.replace('$','').astype('int')\n",
        "pchome.PRIME=pchome.PRIME.replace('是',1)\n",
        "pchome.PRIME=pchome.PRIME.replace('否',0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbpp_2Z09GWV"
      },
      "outputs": [],
      "source": [
        "first = pd.read_csv('/content/drive/MyDrive/Co-lab/dataset/tissue.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7lsM4XQ4KOz"
      },
      "outputs": [],
      "source": [
        "def num(sub,pchome):\n",
        "  customer=np.unique(pchome.iloc[np.where(pchome.GOODS.str.find(sub)!=-1)].MEM_ID)\n",
        "  return(len(customer))\n",
        "\n",
        "def inform(sub,pchome,num):     #找出個別客戶的資料\n",
        "  customer=np.unique(pchome.iloc[np.where(pchome.GOODS.str.find(sub)!=-1)].MEM_ID)\n",
        "\n",
        "  pchome_milk=pchome\n",
        "  pchome_milk['milk_tea']=0\n",
        "  pchome_milk['milk_tea'][pchome.GOODS.str.find(sub)!=-1]=1\n",
        "  test=pchome_milk.loc[pchome['MEM_ID']==customer[num]]\n",
        "  return(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmtWi2ipuxSR"
      },
      "outputs": [],
      "source": [
        "def cus(test):    #建立個別顧客的dataframe\n",
        "  testR=test.groupby(['ORDER_ID']).agg({'DATE_CD':'max'})\n",
        "  c1=testR['DATE_CD'].iloc[:-1]\n",
        "  c2=testR['DATE_CD'].iloc[1:]\n",
        "  c1.index=c2.index\n",
        "  milk_r=pd.DataFrame(c2-c1)\n",
        "  milk_r['date']=100\n",
        "  for i in range(milk_r.shape[0]):\n",
        "    milk_r['date'].iat[i]=milk_r['DATE_CD'].iat[i].days\n",
        "\n",
        "  testF=pd.concat([testR,milk_r,test.groupby(['ORDER_ID']).agg({'milk_tea':'max'})],axis=1)\n",
        "  testF.columns=['DATE_CD','diff','diff_day','milk_tea']\n",
        "  testF['Frequency']=100\n",
        "\n",
        "  testF['weekday']=100\n",
        "  for i in range(len(testF)):\n",
        "    testF['weekday'].iat[i]=testF['DATE_CD'].iat[i].isoweekday()\n",
        "\n",
        "  import collections\n",
        "  for row in range(1,len(testF)):\n",
        "    i=testF.iat[row,1].days\n",
        "    r=row\n",
        "    count=0\n",
        "    while i<31:  #30天內曾經購買過的\n",
        "      if r>1:\n",
        "        r=r-1\n",
        "        i+=testF.iat[r,1].days   #c=1\n",
        "        count+=1\n",
        "      elif r==1:\n",
        "        count+=1\n",
        "        break\n",
        "    partial=testF['milk_tea'].iloc[row-count:row]\n",
        "    count_0=collections.Counter(partial)[0]\n",
        "\n",
        "    testF['Frequency'].iat[row]=partial.shape[0]-count_0\n",
        "\n",
        "  testT=test.groupby(['ORDER_ID']).agg({'TIME_CD':'max'})\n",
        "  testT['hour']=100\n",
        "  for i in range(0,testT.shape[0]):\n",
        "    testT['hour'].iat[i]=testT['TIME_CD'].iat[i].hour\n",
        "  t1=testT[\"hour\"]<5  #1-4\n",
        "  t22=testT[\"hour\"]>4  #5-8\n",
        "  t2=testT[\"hour\"]<9\n",
        "  t33=testT[\"hour\"]>8  #9-12\n",
        "  t3=testT[\"hour\"]<13\n",
        "  t44=testT[\"hour\"]>12 #13-16\n",
        "  t4=testT[\"hour\"]<17\n",
        "  t55=testT[\"hour\"]>17 #17-20\n",
        "  t5=testT[\"hour\"]<21\n",
        "  t66=testT[\"hour\"]>20 #21-24\n",
        "  t6=testT[\"hour\"]<25\n",
        "  testT.loc[testT[t1].index,'hour']=1\n",
        "  testT.loc[testT[t22*t2].index,'hour']=2\n",
        "  testT.loc[testT[t33*t3].index,'hour']=3\n",
        "  testT.loc[testT[t44*t4].index,'hour']=4\n",
        "  testT.loc[testT[t55*t5].index,'hour']=5\n",
        "  testT.loc[testT[t66*t6].index,'hour']=6\n",
        "\n",
        "  final=pd.concat([testF,testT],axis=1)\n",
        "  final=final.drop(labels=[final[0:1].index[0]],axis=0)\n",
        "  return(final)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAEFotYZEAL8"
      },
      "outputs": [],
      "source": [
        "sub='咖啡'\n",
        "number=num(sub,pchome)\n",
        "for i in range(number):\n",
        "  print(i)\n",
        "  if i!=0:\n",
        "    other_test=inform(sub,pchome,i)\n",
        "    other=cus(other_test)\n",
        "    first=pd.concat([first,other],axis=0)\n",
        "  else:\n",
        "    first_test=inform(sub,pchome,i)\n",
        "    first=cus(first_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLdnCMU_p5TF"
      },
      "source": [
        "## 測試關聯分析"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crMkH3UltjZb"
      },
      "outputs": [],
      "source": [
        "def num_cor(sub,pchome):\n",
        "  customer=np.unique(pchome.iloc[np.where(pchome.GOODS.str.find(sub)!=-1)].MEM_ID)\n",
        "  return(len(customer))\n",
        "\n",
        "def inform_correlation(sub,pchome,num,sub2,sub3,sub4):     #找出個別客戶的資料\n",
        "  customer=np.unique(pchome.iloc[np.where(pchome.GOODS.str.find(sub)!=-1)].MEM_ID)\n",
        "\n",
        "  pchome_milk=pchome\n",
        "  pchome_milk['milk_tea']=0\n",
        "  pchome_milk['milk_tea'][pchome.GOODS.str.find(sub)!=-1]=1\n",
        "  pchome_milk['sub2']=0\n",
        "  pchome_milk['sub3']=0\n",
        "  pchome_milk['sub4']=0\n",
        "  pchome_milk['sub2'][pchome.GOODS.str.find(sub2)!=-1]=1\n",
        "  pchome_milk['sub3'][pchome.GOODS.str.find(sub3)!=-1]=1\n",
        "  pchome_milk['sub4'][pchome.GOODS.str.find(sub4)!=-1]=1\n",
        "\n",
        "  test=pchome_milk.loc[pchome['MEM_ID']==customer[num]]\n",
        "  return(test)\n",
        "def cus_cor(test):    #建立個別顧客的dataframe\n",
        "  testR=test.groupby(['ORDER_ID']).agg({'DATE_CD':'max'})\n",
        "  c1=testR['DATE_CD'].iloc[:-1]\n",
        "  c2=testR['DATE_CD'].iloc[1:]\n",
        "  c1.index=c2.index\n",
        "  milk_r=pd.DataFrame(c2-c1)\n",
        "  milk_r['date']=100\n",
        "  for i in range(milk_r.shape[0]):\n",
        "    milk_r['date'].iat[i]=milk_r['DATE_CD'].iat[i].days\n",
        "\n",
        "  testF=pd.concat([testR,milk_r,test.groupby(['ORDER_ID']).agg({'milk_tea':'max'})],axis=1)\n",
        "  testF.columns=['DATE_CD','diff','diff_day','milk_tea']\n",
        "  testF['Frequency']=100\n",
        "\n",
        "  testF['weekday']=100\n",
        "  for i in range(len(testF)):\n",
        "    testF['weekday'].iat[i]=testF['DATE_CD'].iat[i].isoweekday()\n",
        "\n",
        "  import collections\n",
        "  for row in range(1,len(testF)):\n",
        "    i=testF.iat[row,1].days\n",
        "    r=row\n",
        "    count=0\n",
        "    while i<31:  #30天內曾經購買過的\n",
        "      if r>1:\n",
        "        r=r-1\n",
        "        i+=testF.iat[r,1].days   #c=1\n",
        "        count+=1\n",
        "      elif r==1:\n",
        "        count+=1\n",
        "        break\n",
        "    partial=testF['milk_tea'].iloc[row-count:row]\n",
        "    count_0=collections.Counter(partial)[0]\n",
        "\n",
        "    testF['Frequency'].iat[row]=partial.shape[0]-count_0\n",
        "\n",
        "  testT=test.groupby(['ORDER_ID']).agg({'TIME_CD':'max'})\n",
        "  testT['hour']=100\n",
        "  for i in range(0,testT.shape[0]):\n",
        "    testT['hour'].iat[i]=testT['TIME_CD'].iat[i].hour\n",
        "  t1=testT[\"hour\"]<5  #1-4\n",
        "  t22=testT[\"hour\"]>4  #5-8\n",
        "  t2=testT[\"hour\"]<9\n",
        "  t33=testT[\"hour\"]>8  #9-12\n",
        "  t3=testT[\"hour\"]<13\n",
        "  t44=testT[\"hour\"]>12 #13-16\n",
        "  t4=testT[\"hour\"]<17\n",
        "  t55=testT[\"hour\"]>17 #17-20\n",
        "  t5=testT[\"hour\"]<21\n",
        "  t66=testT[\"hour\"]>20 #21-24\n",
        "  t6=testT[\"hour\"]<25\n",
        "  testT.loc[testT[t1].index,'hour']=1\n",
        "  testT.loc[testT[t22*t2].index,'hour']=2\n",
        "  testT.loc[testT[t33*t3].index,'hour']=3\n",
        "  testT.loc[testT[t44*t4].index,'hour']=4\n",
        "  testT.loc[testT[t55*t5].index,'hour']=5\n",
        "  testT.loc[testT[t66*t6].index,'hour']=6\n",
        "\n",
        "  final=pd.concat([testF,testT,test.groupby(['ORDER_ID']).agg({'sub2':'max'}),test.groupby(['ORDER_ID']).agg({'sub3':'max'}),test.groupby(['ORDER_ID']).agg({'sub4':'max'})],axis=1)\n",
        "  final=final.drop(labels=[final[0:1].index[0]],axis=0)\n",
        "  return(final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAZvZobjIXpS"
      },
      "outputs": [],
      "source": [
        "#找出買過奶茶的顧客的交易資料\n",
        "sub='奶茶'\n",
        "number=num_cor(sub,pchome)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuazY_DYQOIh"
      },
      "source": [
        "## 跑模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJr8H7okItns"
      },
      "outputs": [],
      "source": [
        "f=first.drop(labels=['diff','TIME_CD'],axis=1)\n",
        "time='2020-9-10'\n",
        "f['DATE_CD']=pd.to_datetime(f['DATE_CD'])\n",
        "f_up=f[f['DATE_CD']<pd.to_datetime(time)]\n",
        "f_down=f[f['DATE_CD']>pd.to_datetime(time)]\n",
        "f_up=f_up.drop(labels=['DATE_CD'],axis=1)\n",
        "f_down=f_down.drop(labels=['DATE_CD'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZp3joQeH5P6"
      },
      "outputs": [],
      "source": [
        "train_x=f_up.drop(labels=['milk_tea'],axis=1)\n",
        "train_y=f_up['milk_tea']\n",
        "test_x=f_down.drop(labels=['milk_tea'],axis=1)\n",
        "test_y=f_down['milk_tea']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msYl3zNpqbmf"
      },
      "outputs": [],
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "LR = LogisticRegression(penalty = 'none')\n",
        "RF = RandomForestClassifier(n_estimators=100)\n",
        "MLP = MLPClassifier(hidden_layer_sizes = (256,128), activation=\"relu\", random_state=1)\n",
        "SVM = svm.SVC(gamma=0.001, C=10., kernel='linear', max_iter=10000, probability=True)\n",
        "XGB = XGBClassifier(n_estimators=100, learning_rate= 0.3, max_depth=6)\n",
        "LGBM = lgb.LGBMClassifier(application='multiclass', boosting='gbdt', learning_rate=0.1,\n",
        "                            max_depth=-5, feature_fraction=0.5, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "re7Ux0axtBDe"
      },
      "outputs": [],
      "source": [
        "#訓練\n",
        "index1=np.random.choice(f_up.loc[f_up['milk_tea']==1].index,10000)\n",
        "index0=np.random.choice(f_up.loc[f_up['milk_tea']==0].index,15000)\n",
        "choice1=f_up.loc[index1]\n",
        "choice0=f_up.loc[index0]\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "train=shuffle(pd.concat([choice1,choice0], axis=0))\n",
        "test=f_down"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ne1m-27tyAZ1"
      },
      "outputs": [],
      "source": [
        "x_train=train.drop(labels=['milk_tea'],axis=1)\n",
        "y_train=train['milk_tea']\n",
        "x_test=test.drop(labels=['milk_tea'],axis=1)\n",
        "y_test=test['milk_tea']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgB6gF8zyhdf"
      },
      "outputs": [],
      "source": [
        "knn.fit(x_train, y_train)\n",
        "LR.fit(x_train, y_train)\n",
        "RF.fit(x_train, y_train)\n",
        "MLP.fit(x_train, y_train)\n",
        "LGBM.fit(x_train, y_train)\n",
        "XGB.fit(x_train, y_train)\n",
        "\n",
        "knn_predicted = knn.predict(x_test)\n",
        "LR_predicted = LR.predict(x_test)\n",
        "RF_predicted = RF.predict(x_test)\n",
        "MLP_predicted = MLP.predict(x_test)\n",
        "LGBM_predicted = LGBM.predict(x_test)\n",
        "XGB_predicted = XGB.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOHS8Xk3jK0e",
        "outputId": "74c3325c-d34e-40e5-f15f-9ce8230f70af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 1, ..., 0, 1, 0])"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "LGBM_predicted+XGB_predicted+RF_predicted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzDURGxJ2wo7"
      },
      "outputs": [],
      "source": [
        "ttt=LGBM_predicted+XGB_predicted+RF_predicted\n",
        "ttt[np.where(ttt>1)]=1"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
